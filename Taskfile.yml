version: "3"

vars:
  PROJECT_ROOT:
    sh: pwd
  POSTGRES_CONTAINER: strato-postgres
  SPICEDB_CONTAINER: strato-spicedb
  VALKEY_CONTAINER: strato-valkey
  LOKI_CONTAINER: strato-loki
  OTEL_COLLECTOR_CONTAINER: strato-otel-collector
  SPIRE_SERVER_CONTAINER: strato-spire-server
  SPIRE_AGENT_CONTAINER: strato-spire-agent
  ENVOY_CONTAINER: strato-envoy
  POSTGRES_DB: vapor_database
  POSTGRES_USER: vapor_username
  POSTGRES_PASSWORD: vapor_password
  SPICEDB_KEY: strato-dev-key
  SPIRE_TRUST_DOMAIN: strato.local

env:
  DATABASE_HOST: localhost
  DATABASE_PORT: "5432"
  DATABASE_NAME: vapor_database
  DATABASE_USERNAME: vapor_username
  DATABASE_PASSWORD: vapor_password
  SPICEDB_ENDPOINT: http://localhost:8081
  SPICEDB_PRESHARED_KEY: strato-dev-key
  WEBAUTHN_RELYING_PARTY_ID: localhost
  WEBAUTHN_RELYING_PARTY_NAME: Strato
  WEBAUTHN_RELYING_PARTY_ORIGIN: http://localhost:3000
  # Disable OpenTelemetry for local development
  OTEL_METRICS_ENABLED: "false"
  OTEL_LOGS_ENABLED: "false"
  OTEL_TRACES_ENABLED: "false"
  # Enable dev auth bypass for local development
  DEV_AUTH_BYPASS: "true"
  # Valkey configuration
  VALKEY_HOST: localhost
  VALKEY_PORT: "6379"
  # Loki configuration for VM logs
  LOKI_ENDPOINT: "http://localhost:3100"

tasks:
  # ============================================================================
  # Main Development Task
  # ============================================================================
  dev:
    desc: Start backend development environment (run frontend separately)
    cmds:
      - task: start-postgres
      - task: start-spicedb
      - task: start-valkey
      - task: start-loki
      - task: start-otel-collector
      - task: load-spicedb-schema
      - task: start-control-plane
      - task: create-agent-config
      - task: create-agent-token
      - task: start-agent
      - task: create-test-vm
      - |
        echo ""
        echo "üéâ Backend development environment is running!"
        echo ""
        echo "üìä Service URLs:"
        echo "   ‚Ä¢ Control Plane API:  http://localhost:8080"
        echo "   ‚Ä¢ SpiceDB Admin:      http://localhost:8081"
        echo "   ‚Ä¢ PostgreSQL:         localhost:5432"
        echo "   ‚Ä¢ Valkey:             localhost:6379"
        echo "   ‚Ä¢ Loki:               localhost:3100"
        echo "   ‚Ä¢ OTel Collector:     localhost:4317 (gRPC), localhost:4318 (HTTP)"
        echo ""
        echo "üé® Frontend:"
        echo "   Run 'task dev-frontend' in another terminal"
        echo "   Frontend will be at http://localhost:3000"
        echo ""
        echo "üìã Logs:"
        echo "   ‚Ä¢ Control Plane:  tail -f /tmp/strato-control-plane.log"
        echo "   ‚Ä¢ Agent:          tail -f /tmp/strato-agent.log"
        echo ""
        echo "‚ö†Ô∏è  To stop all services, run: task stop"
        echo "‚ö†Ô∏è  To clean everything up, run: task clean"

  dev-compose:
    desc: Start full development environment via Docker Compose
    cmds:
      - echo "üê≥ Starting Docker Compose environment..."
      - docker compose up --build

  # ============================================================================
  # Infrastructure Tasks
  # ============================================================================
  start-postgres:
    desc: Start PostgreSQL database container
    cmds:
      - echo "üêò Starting PostgreSQL..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.POSTGRES_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.POSTGRES_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  PostgreSQL container already exists. Starting it..."
          docker start {{.POSTGRES_CONTAINER}}
        else
          docker run -d \
            --name {{.POSTGRES_CONTAINER}} \
            -e POSTGRES_DB={{.POSTGRES_DB}} \
            -e POSTGRES_USER={{.POSTGRES_USER}} \
            -e POSTGRES_PASSWORD={{.POSTGRES_PASSWORD}} \
            -p 5432:5432 \
            postgres:16-alpine
        fi
      - echo "‚è≥ Waiting for PostgreSQL to be ready..."
      - sleep 3
      - |
        for i in $(seq 1 30); do
          if docker exec {{.POSTGRES_CONTAINER}} pg_isready -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} > /dev/null 2>&1; then
            echo "‚úÖ PostgreSQL is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå PostgreSQL did not become ready in time"
        exit 1

  start-spicedb:
    desc: Start SpiceDB authorization service
    cmds:
      - echo "üîê Starting SpiceDB..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.SPICEDB_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.SPICEDB_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  SpiceDB container already exists. Removing and recreating..."
          docker rm -f {{.SPICEDB_CONTAINER}}
        fi
      - |
        POSTGRES_IP=$(docker inspect -f '{{`{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}`}}' {{.POSTGRES_CONTAINER}})
        CONN_STRING="postgres://{{.POSTGRES_USER}}:{{.POSTGRES_PASSWORD}}@${POSTGRES_IP}:5432/{{.POSTGRES_DB}}?sslmode=disable"

        echo "üîÑ Running SpiceDB migrations..."
        docker run --rm \
          --network host \
          -e SPICEDB_DATASTORE_ENGINE=postgres \
          -e "SPICEDB_DATASTORE_CONN_URI=${CONN_STRING}" \
          authzed/spicedb:v1.35.3 \
          migrate head

        echo "‚ñ∂Ô∏è  Starting SpiceDB server..."
        docker run -d \
          --name {{.SPICEDB_CONTAINER}} \
          --network host \
          -e SPICEDB_DATASTORE_ENGINE=postgres \
          -e "SPICEDB_DATASTORE_CONN_URI=${CONN_STRING}" \
          -e SPICEDB_GRPC_PRESHARED_KEY={{.SPICEDB_KEY}} \
          authzed/spicedb:v1.35.3 \
          serve \
          --grpc-preshared-key {{.SPICEDB_KEY}} \
          --http-enabled \
          --http-addr :8081 \
          --grpc-addr :50051
      - echo "‚è≥ Waiting for SpiceDB to be ready..."
      - sleep 3
      - |
        for i in $(seq 1 30); do
          if curl -sf http://localhost:8081/healthz > /dev/null 2>&1; then
            echo "‚úÖ SpiceDB is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå SpiceDB did not become ready in time"
        exit 1

  start-valkey:
    desc: Start Valkey (Redis-compatible) container
    cmds:
      - echo "üî¥ Starting Valkey..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.VALKEY_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.VALKEY_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  Valkey container already exists. Starting it..."
          docker start {{.VALKEY_CONTAINER}}
        else
          docker run -d \
            --name {{.VALKEY_CONTAINER}} \
            -p 6379:6379 \
            valkey/valkey:8.0-alpine
        fi
      - echo "‚è≥ Waiting for Valkey to be ready..."
      - sleep 2
      - |
        for i in $(seq 1 30); do
          if docker exec {{.VALKEY_CONTAINER}} valkey-cli ping 2>/dev/null | grep -q "PONG"; then
            echo "‚úÖ Valkey is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå Valkey did not become ready in time"
        exit 1

  start-loki:
    desc: Start Loki log aggregation service
    cmds:
      - echo "üìä Starting Loki..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.LOKI_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.LOKI_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  Loki container already exists. Starting it..."
          docker start {{.LOKI_CONTAINER}}
        else
          docker run -d \
            --name {{.LOKI_CONTAINER}} \
            -p 3100:3100 \
            grafana/loki:2.9.4 \
            -config.file=/etc/loki/local-config.yaml
        fi
      - echo "‚è≥ Waiting for Loki to be ready..."
      - sleep 3
      - |
        for i in $(seq 1 30); do
          if curl -sf http://localhost:3100/ready > /dev/null 2>&1; then
            echo "‚úÖ Loki is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå Loki did not become ready in time"
        exit 1

  start-otel-collector:
    desc: Start OpenTelemetry Collector for logs, metrics, and traces
    cmds:
      - echo "üì° Starting OpenTelemetry Collector..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.OTEL_COLLECTOR_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.OTEL_COLLECTOR_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  OTel Collector container already exists. Removing and recreating..."
          docker rm -f {{.OTEL_COLLECTOR_CONTAINER}}
        fi
      - |
        # Get Loki container IP for collector to push logs
        LOKI_IP=$(docker inspect -f '{{`{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}`}}' {{.LOKI_CONTAINER}})

        docker run -d \
          --name {{.OTEL_COLLECTOR_CONTAINER}} \
          -p 4317:4317 \
          -p 4318:4318 \
          -p 8888:8888 \
          -p 8889:8889 \
          -v "{{.PROJECT_ROOT}}/observability/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro" \
          -e LOKI_ENDPOINT="http://${LOKI_IP}:3100" \
          otel/opentelemetry-collector-contrib:0.112.0 \
          --config=/etc/otel-collector-config.yaml
      - echo "‚è≥ Waiting for OTel Collector to be ready..."
      - sleep 3
      - |
        for i in $(seq 1 30); do
          if curl -sf http://localhost:8888/metrics > /dev/null 2>&1; then
            echo "‚úÖ OTel Collector is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå OTel Collector did not become ready in time"
        exit 1

  # ============================================================================
  # SPIFFE/SPIRE Infrastructure Tasks
  # ============================================================================
  start-spire-server:
    desc: Start SPIRE Server container
    cmds:
      - echo "üîê Starting SPIRE Server..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.SPIRE_SERVER_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.SPIRE_SERVER_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  SPIRE Server container already exists. Removing and recreating..."
          docker rm -f {{.SPIRE_SERVER_CONTAINER}}
        fi
      - |
        # Create SPIRE Server config directory
        mkdir -p /tmp/spire-server

        # Create SPIRE Server configuration
        # Using ports 8085 (gRPC) and 8086 (health) to avoid conflicts with SpiceDB (8081) and control plane (8080)
        cat > /tmp/spire-server/server.conf << 'EOF'
        server {
            bind_address = "0.0.0.0"
            bind_port = "8085"
            trust_domain = "{{.SPIRE_TRUST_DOMAIN}}"
            data_dir = "/var/lib/spire/server"
            log_level = "INFO"

            ca_ttl = "168h"
            default_x509_svid_ttl = "1h"
            default_jwt_svid_ttl = "5m"
        }

        plugins {
            DataStore "sql" {
                plugin_data {
                    database_type = "sqlite3"
                    connection_string = "/var/lib/spire/server/datastore.sqlite3"
                }
            }

            NodeAttestor "join_token" {}

            KeyManager "disk" {
                plugin_data {
                    keys_path = "/var/lib/spire/server/keys"
                }
            }
        }

        health_checks {
            listener_enabled = true
            bind_address = "0.0.0.0"
            bind_port = "8086"
            live_path = "/live"
            ready_path = "/ready"
        }
        EOF

        # Start SPIRE Server
        docker run -d \
          --name {{.SPIRE_SERVER_CONTAINER}} \
          --network host \
          -v /tmp/spire-server:/etc/spire/server:ro \
          -v spire-server-data:/var/lib/spire/server \
          ghcr.io/spiffe/spire-server:1.9.6 \
          -config /etc/spire/server/server.conf
      - echo "‚è≥ Waiting for SPIRE Server to be ready..."
      - sleep 3
      - |
        for i in $(seq 1 30); do
          if curl -sf http://localhost:8086/ready > /dev/null 2>&1; then
            echo "‚úÖ SPIRE Server is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå SPIRE Server did not become ready in time"
        exit 1

  create-spire-join-token:
    desc: Create SPIRE join token for agent attestation
    cmds:
      - echo "üé´ Creating SPIRE join token..."
      - |
        JOIN_TOKEN=$(docker exec {{.SPIRE_SERVER_CONTAINER}} \
          /opt/spire/bin/spire-server token generate \
          -spiffeID spiffe://{{.SPIRE_TRUST_DOMAIN}}/spire-agent \
          -ttl 3600 2>/dev/null | grep "Token:" | awk '{print $2}')

        if [ -z "$JOIN_TOKEN" ]; then
          echo "‚ùå Failed to generate join token"
          exit 1
        fi

        echo "$JOIN_TOKEN" > /tmp/spire-join-token.txt
        echo "‚úÖ Join token created and saved to /tmp/spire-join-token.txt"

  start-spire-agent:
    desc: Start SPIRE Agent container
    deps: [create-spire-join-token]
    cmds:
      - echo "üîê Starting SPIRE Agent..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.SPIRE_AGENT_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.SPIRE_AGENT_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  SPIRE Agent container already exists. Removing and recreating..."
          docker rm -f {{.SPIRE_AGENT_CONTAINER}}
        fi
      - |
        # Create SPIRE Agent config directory
        mkdir -p /tmp/spire-agent
        mkdir -p /tmp/spire-sockets

        JOIN_TOKEN=$(cat /tmp/spire-join-token.txt)

        # Create SPIRE Agent configuration
        # Connects to SPIRE Server on port 8085 (avoiding SpiceDB port conflict)
        cat > /tmp/spire-agent/agent.conf << EOF
        agent {
            data_dir = "/var/lib/spire/agent"
            log_level = "INFO"
            server_address = "127.0.0.1"
            server_port = "8085"
            socket_path = "/var/run/spire/sockets/workload.sock"
            trust_domain = "{{.SPIRE_TRUST_DOMAIN}}"
            join_token = "${JOIN_TOKEN}"
            insecure_bootstrap = true

            sds {
                default_svid_name = "default"
                default_bundle_name = "ROOTCA"
            }
        }

        plugins {
            NodeAttestor "join_token" {}

            KeyManager "disk" {
                plugin_data {
                    directory = "/var/lib/spire/agent"
                }
            }

            WorkloadAttestor "unix" {
                plugin_data {
                    discover_workload_path = true
                }
            }
        }

        health_checks {
            listener_enabled = true
            bind_address = "0.0.0.0"
            bind_port = "8082"
            live_path = "/live"
            ready_path = "/ready"
        }
        EOF

        # Start SPIRE Agent
        # Note: --privileged is required for the unix workload attestor to read /proc/<pid>/exe
        docker run -d \
          --name {{.SPIRE_AGENT_CONTAINER}} \
          --network host \
          --pid host \
          --privileged \
          -v /tmp/spire-agent:/etc/spire/agent:ro \
          -v /tmp/spire-sockets:/var/run/spire/sockets \
          -v spire-agent-data:/var/lib/spire/agent \
          ghcr.io/spiffe/spire-agent:1.9.6 \
          -config /etc/spire/agent/agent.conf
      - echo "‚è≥ Waiting for SPIRE Agent to be ready..."
      - sleep 5
      - |
        for i in $(seq 1 30); do
          if curl -sf http://localhost:8082/ready > /dev/null 2>&1; then
            echo "‚úÖ SPIRE Agent is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå SPIRE Agent did not become ready in time"
        exit 1

  create-spire-entries:
    desc: Create SPIRE registration entries for control plane and agent
    cmds:
      - echo "üìã Creating SPIRE registration entries..."
      - |
        # Get the current SPIRE Agent's SPIFFE ID (required for parent ID)
        AGENT_SPIFFE_ID=$(docker exec {{.SPIRE_SERVER_CONTAINER}} \
          /opt/spire/bin/spire-server agent list 2>/dev/null | \
          grep "SPIFFE ID" | head -1 | awk '{print $4}')

        if [ -z "$AGENT_SPIFFE_ID" ]; then
          echo "‚ùå No SPIRE Agent found. Run start-spire-agent first."
          exit 1
        fi
        echo "Using SPIRE Agent: $AGENT_SPIFFE_ID"

        # Create entry for control plane (Envoy runs as uid 101)
        docker exec {{.SPIRE_SERVER_CONTAINER}} \
          /opt/spire/bin/spire-server entry create \
          -spiffeID spiffe://{{.SPIRE_TRUST_DOMAIN}}/control-plane \
          -parentID "$AGENT_SPIFFE_ID" \
          -selector unix:uid:101 \
          -ttl 3600 || true
        echo "‚úÖ Control plane entry created (uid:101 for Envoy)"

        # Create entry for strato agent (runs as root, uid 0)
        docker exec {{.SPIRE_SERVER_CONTAINER}} \
          /opt/spire/bin/spire-server entry create \
          -spiffeID spiffe://{{.SPIRE_TRUST_DOMAIN}}/agent/strato-dev \
          -parentID "$AGENT_SPIFFE_ID" \
          -selector unix:uid:0 \
          -ttl 3600 || true
        echo "‚úÖ Strato agent entry created (uid:0 for Swift agent)"
      - echo "‚úÖ SPIRE entries created!"

  fetch-agent-svid:
    desc: Fetch SVID for the Strato Agent and write to files
    cmds:
      - echo "üîê Fetching SVID for Strato Agent..."
      - |
        # Create output directories (both on host and inside container mount)
        mkdir -p /tmp/strato-spiffe
        mkdir -p /tmp/spire-sockets/svid

        # Use spire-agent CLI from inside the container to fetch SVIDs
        # The output goes to mounted volume so host can read it
        docker exec {{.SPIRE_AGENT_CONTAINER}} \
          /opt/spire/bin/spire-agent api fetch x509 \
          -socketPath /var/run/spire/sockets/workload.sock \
          -write /var/run/spire/sockets/svid

        # Copy the SVID files to host-accessible location
        cp /tmp/spire-sockets/svid/svid.0.pem /tmp/strato-spiffe/svid.pem
        cp /tmp/spire-sockets/svid/svid.0.key /tmp/strato-spiffe/svid.key
        cp /tmp/spire-sockets/svid/bundle.0.pem /tmp/strato-spiffe/bundle.pem

        # Verify files were created
        if [ -f /tmp/strato-spiffe/svid.pem ] && [ -f /tmp/strato-spiffe/svid.key ]; then
          echo "‚úÖ SVID files written to /tmp/strato-spiffe/"
          ls -la /tmp/strato-spiffe/
        else
          echo "‚ùå Failed to fetch SVID files"
          exit 1
        fi
      - echo "‚úÖ SVID fetch complete!"

  start-envoy:
    desc: Start Envoy proxy for mTLS termination
    cmds:
      - echo "üåê Starting Envoy proxy..."
      - |
        EXISTING=$(docker ps -a --filter "name={{.ENVOY_CONTAINER}}" --format "{{`{{.Names}}`}}")
        if [ "$EXISTING" = "{{.ENVOY_CONTAINER}}" ]; then
          echo "‚ö†Ô∏è  Envoy container already exists. Removing and recreating..."
          docker rm -f {{.ENVOY_CONTAINER}}
        fi
      - |
        # Create Envoy config directory
        mkdir -p /tmp/envoy

        # Create Envoy configuration
        cat > /tmp/envoy/envoy.yaml << 'EOF'
        node:
          id: strato-control-plane
          cluster: strato-control-plane

        static_resources:
          listeners:
            - name: agent_mtls_listener
              address:
                socket_address:
                  address: 0.0.0.0
                  port_value: 8443
              filter_chains:
                - transport_socket:
                    name: envoy.transport_sockets.tls
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
                      require_client_certificate: true
                      common_tls_context:
                        tls_certificate_sds_secret_configs:
                          - name: "spiffe://strato.local/control-plane"
                            sds_config:
                              resource_api_version: V3
                              api_config_source:
                                api_type: GRPC
                                transport_api_version: V3
                                grpc_services:
                                  - envoy_grpc:
                                      cluster_name: spire_agent
                        validation_context_sds_secret_config:
                          name: "spiffe://strato.local"
                          sds_config:
                            resource_api_version: V3
                            api_config_source:
                              api_type: GRPC
                              transport_api_version: V3
                              grpc_services:
                                - envoy_grpc:
                                    cluster_name: spire_agent
                  filters:
                    - name: envoy.filters.network.http_connection_manager
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                        stat_prefix: agent_mtls
                        codec_type: AUTO
                        upgrade_configs:
                          - upgrade_type: websocket
                        forward_client_cert_details: SANITIZE_SET
                        set_current_client_cert_details:
                          uri: true
                          subject: true
                        route_config:
                          name: agent_route
                          virtual_hosts:
                            - name: control_plane
                              domains: ["*"]
                              routes:
                                - match:
                                    prefix: "/"
                                  route:
                                    cluster: control_plane_local
                                    timeout: 0s
                        http_filters:
                          - name: envoy.filters.http.router
                            typed_config:
                              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router

            - name: health_listener
              address:
                socket_address:
                  address: 0.0.0.0
                  port_value: 8444
              filter_chains:
                - filters:
                    - name: envoy.filters.network.http_connection_manager
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                        stat_prefix: health
                        codec_type: AUTO
                        route_config:
                          name: health_route
                          virtual_hosts:
                            - name: health
                              domains: ["*"]
                              routes:
                                - match:
                                    prefix: "/ready"
                                  direct_response:
                                    status: 200
                                    body:
                                      inline_string: "OK"
                        http_filters:
                          - name: envoy.filters.http.router
                            typed_config:
                              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router

          clusters:
            - name: control_plane_local
              connect_timeout: 5s
              type: STATIC
              lb_policy: ROUND_ROBIN
              load_assignment:
                cluster_name: control_plane_local
                endpoints:
                  - lb_endpoints:
                      - endpoint:
                          address:
                            socket_address:
                              address: 127.0.0.1
                              port_value: 8080

            - name: spire_agent
              connect_timeout: 5s
              type: STATIC
              lb_policy: ROUND_ROBIN
              typed_extension_protocol_options:
                envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
                  "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
                  explicit_http_config:
                    http2_protocol_options: {}
              load_assignment:
                cluster_name: spire_agent
                endpoints:
                  - lb_endpoints:
                      - endpoint:
                          address:
                            pipe:
                              path: /var/run/spire/sockets/workload.sock

        admin:
          address:
            socket_address:
              address: 127.0.0.1
              port_value: 9901
        EOF

        # Start Envoy
        # Note: --pid host is required for SPIRE Agent to attest Envoy's workload identity
        docker run -d \
          --name {{.ENVOY_CONTAINER}} \
          --network host \
          --pid host \
          -v /tmp/envoy:/etc/envoy:ro \
          -v /tmp/spire-sockets:/var/run/spire/sockets:ro \
          envoyproxy/envoy:v1.31.0 \
          -c /etc/envoy/envoy.yaml \
          --log-level info
      - echo "‚è≥ Waiting for Envoy to be ready..."
      - sleep 3
      - |
        for i in $(seq 1 30); do
          if curl -sf http://localhost:8444/ready > /dev/null 2>&1; then
            echo "‚úÖ Envoy is ready!"
            exit 0
          fi
          sleep 1
        done
        echo "‚ùå Envoy did not become ready in time"
        exit 1

  # ============================================================================
  # SPIFFE Development Environment
  # ============================================================================
  dev-spiffe:
    desc: Start SPIFFE development environment (run frontend separately)
    cmds:
      - task: start-postgres
      - task: start-spicedb
      - task: start-valkey
      - task: start-loki
      - task: start-otel-collector
      - task: start-spire-server
      - task: start-spire-agent
      - task: create-spire-entries
      - task: start-envoy
      - task: load-spicedb-schema
      - task: start-control-plane-spiffe
      - task: fetch-agent-svid
      - task: create-agent-config-spiffe
      - task: start-agent-spiffe
      - task: create-test-vm
      - |
        echo ""
        echo "üéâ SPIFFE Development environment is running!"
        echo ""
        echo "üìä Service URLs:"
        echo "   ‚Ä¢ Control Plane API:  http://localhost:8080"
        echo "   ‚Ä¢ Agent mTLS:         https://localhost:8443"
        echo "   ‚Ä¢ SPIRE Server:       localhost:8085 (gRPC)"
        echo "   ‚Ä¢ SpiceDB:            localhost:8081 (gRPC)"
        echo "   ‚Ä¢ PostgreSQL:         localhost:5432"
        echo "   ‚Ä¢ Valkey:             localhost:6379"
        echo "   ‚Ä¢ Loki:               localhost:3100"
        echo "   ‚Ä¢ OTel Collector:     localhost:4317 (gRPC), localhost:4318 (HTTP)"
        echo "   ‚Ä¢ Envoy Admin:        http://localhost:9901"
        echo ""
        echo "üé® Frontend:"
        echo "   Run 'task dev-frontend' in another terminal"
        echo "   Frontend will be at http://localhost:3000"
        echo ""
        echo "üîê SPIFFE/SPIRE:"
        echo "   ‚Ä¢ Trust Domain:      {{.SPIRE_TRUST_DOMAIN}}"
        echo "   ‚Ä¢ Workload Socket:   /tmp/spire-sockets/workload.sock"
        echo ""
        echo "üìã Logs:"
        echo "   ‚Ä¢ Control Plane:     tail -f /tmp/strato-control-plane.log"
        echo "   ‚Ä¢ Agent:             tail -f /tmp/strato-agent.log"
        echo "   ‚Ä¢ SPIRE Server:      docker logs -f {{.SPIRE_SERVER_CONTAINER}}"
        echo "   ‚Ä¢ SPIRE Agent:       docker logs -f {{.SPIRE_AGENT_CONTAINER}}"
        echo "   ‚Ä¢ Envoy:             docker logs -f {{.ENVOY_CONTAINER}}"
        echo ""
        echo "‚ö†Ô∏è  To stop all services, run: task stop-spiffe"

  create-agent-config-spiffe:
    desc: Create agent configuration file with SPIFFE enabled
    cmds:
      - echo "üìù Creating agent configuration with SPIFFE..."
      - |
        cat > "{{.PROJECT_ROOT}}/config.toml" << 'EOF'
        # Strato Agent Configuration with SPIFFE mTLS
        # Connects to control plane via Envoy mTLS proxy
        control_plane_url = "wss://localhost:8443/agent/ws"
        qemu_socket_dir = "/tmp/strato-qemu-sockets"
        log_level = "debug"
        network_mode = "user"

        [spiffe]
        enabled = true
        trust_domain = "strato.local"
        # Using file-based SVIDs (fetched via fetch-agent-svid task)
        source_type = "files"
        certificate_path = "/tmp/strato-spiffe/svid.pem"
        private_key_path = "/tmp/strato-spiffe/svid.key"
        trust_bundle_path = "/tmp/strato-spiffe/bundle.pem"
        EOF
      - echo "‚úÖ Agent config created at {{.PROJECT_ROOT}}/config.toml"

  start-agent-spiffe:
    desc: Build and start the agent service with SPIFFE mTLS authentication
    cmds:
      - echo "ü§ñ Building and starting agent with SPIFFE mTLS..."
      - echo "üî® Building agent..."
      - swift build --package-path "{{.PROJECT_ROOT}}/agent"
      - mkdir -p /tmp/strato-qemu-sockets
      - |
        echo "‚ñ∂Ô∏è  Starting agent with SPIFFE mTLS..."
        touch /tmp/strato-agent.log

        # Verify SVID files exist
        if [ ! -f /tmp/strato-spiffe/svid.pem ]; then
          echo "‚ùå SVID files not found. Run 'task fetch-agent-svid' first."
          exit 1
        fi

        # Start agent with SPIFFE mTLS (uses config from create-agent-config-spiffe)
        nohup swift run --package-path "{{.PROJECT_ROOT}}/agent" StratoAgent \
          --config-file "{{.PROJECT_ROOT}}/config.toml" \
          --debug > /tmp/strato-agent.log 2>&1 &
        echo $! > /tmp/strato-agent.pid
      - echo "‚úÖ Agent started with SPIFFE mTLS!"
      - echo "üìã Logs available at /tmp/strato-agent.log"
      - sleep 5

  stop-spiffe:
    desc: Stop all SPIFFE-related services
    cmds:
      - echo "üõë Stopping SPIFFE services..."
      - task: stop
      - docker stop {{.ENVOY_CONTAINER}} 2>/dev/null || true
      - docker stop {{.SPIRE_AGENT_CONTAINER}} 2>/dev/null || true
      - docker stop {{.SPIRE_SERVER_CONTAINER}} 2>/dev/null || true
      - echo "‚úÖ SPIFFE services stopped!"

  clean-spiffe:
    desc: Clean up all SPIFFE-related containers and data
    deps: [stop-spiffe]
    cmds:
      - echo "üßπ Cleaning up SPIFFE resources..."
      - docker rm -f {{.ENVOY_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.SPIRE_AGENT_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.SPIRE_SERVER_CONTAINER}} 2>/dev/null || true
      - docker volume rm spire-server-data 2>/dev/null || true
      - docker volume rm spire-agent-data 2>/dev/null || true
      - rm -rf /tmp/spire-server /tmp/spire-agent /tmp/spire-sockets /tmp/envoy
      - rm -f /tmp/spire-join-token.txt
      - task: clean
      - echo "‚úÖ SPIFFE cleanup complete!"

  load-spicedb-schema:
    desc: Load SpiceDB authorization schema
    cmds:
      - echo "üìã Loading SpiceDB schema..."
      - |
        if [ ! -f "{{.PROJECT_ROOT}}/spicedb/schema.zed" ]; then
          echo "‚ùå SpiceDB schema not found at {{.PROJECT_ROOT}}/spicedb/schema.zed"
          exit 1
        fi
      - |
        docker run --rm \
          --network host \
          -v "{{.PROJECT_ROOT}}/spicedb/schema.zed:/schema.zed:ro" \
          authzed/zed:latest \
          schema write /schema.zed \
          --endpoint localhost:50051 \
          --token {{.SPICEDB_KEY}} \
          --insecure
      - echo "‚úÖ SpiceDB schema loaded!"

  # ============================================================================
  # Application Tasks
  # ============================================================================
  build-frontend:
    desc: Build the Next.js frontend
    cmds:
      - echo "üé® Building frontend..."
      - |
        cd "{{.PROJECT_ROOT}}/control-plane/web"
        if [ ! -d "node_modules" ]; then
          echo "üì¶ Installing dependencies..."
          bun install
        fi
        echo "üî® Building Next.js app..."
        bun run build
      - echo "‚úÖ Frontend built!"

  dev-frontend:
    desc: Start Next.js frontend in development mode (hot reload)
    cmds:
      - echo "üé® Starting frontend dev server..."
      - |
        cd "{{.PROJECT_ROOT}}/control-plane/web"
        if [ ! -d "node_modules" ]; then
          echo "üì¶ Installing dependencies..."
          bun install
        fi
      - cd "{{.PROJECT_ROOT}}/control-plane/web" && bun run dev

  start-frontend:
    desc: Start Next.js frontend in production mode
    cmds:
      - echo "üé® Starting frontend..."
      - |
        cd "{{.PROJECT_ROOT}}/control-plane/web"
        bun run build
        touch /tmp/strato-frontend.log
        nohup bun run start > /tmp/strato-frontend.log 2>&1 &
        echo $! > /tmp/strato-frontend.pid
      - echo "‚úÖ Frontend started on port 3000!"
      - echo "üìã Logs available at /tmp/strato-frontend.log"

  start-control-plane:
    desc: Build and start the control-plane service
    cmds:
      - echo "üöÄ Building and starting control-plane..."
      - echo "üî® Building control-plane..."
      - swift build --package-path "{{.PROJECT_ROOT}}/control-plane"
      - echo "‚ñ∂Ô∏è  Starting control-plane..."
      - |
        touch /tmp/strato-control-plane.log
        cd "{{.PROJECT_ROOT}}/control-plane" && nohup swift run > /tmp/strato-control-plane.log 2>&1 &
        echo $! > /tmp/strato-control-plane.pid
      - echo "‚è≥ Waiting for control-plane to be ready..."
      - sleep 5
      - |
        for i in $(seq 1 60); do
          if curl -sf http://localhost:8080/health/live > /dev/null 2>&1; then
            echo "‚úÖ Control-plane is ready!"
            echo "üìã Logs available at: /tmp/strato-control-plane.log"
            exit 0
          fi
          sleep 2
        done
        echo "‚ö†Ô∏è  Control-plane may not be fully ready. Check logs at /tmp/strato-control-plane.log"

  start-control-plane-spiffe:
    desc: Build and start the control-plane with SPIFFE/SPIRE mTLS enabled
    cmds:
      - echo "üöÄ Building and starting control-plane with SPIFFE/SPIRE..."
      - echo "üî® Building control-plane..."
      - swift build --package-path "{{.PROJECT_ROOT}}/control-plane"
      - echo "‚ñ∂Ô∏è  Starting control-plane with SPIFFE enabled..."
      - |
        touch /tmp/strato-control-plane.log
        cd "{{.PROJECT_ROOT}}/control-plane" && \
        SPIRE_ENABLED=true \
        SPIRE_TRUST_DOMAIN={{.SPIRE_TRUST_DOMAIN}} \
        SPIRE_TRUST_BUNDLE_PATH=/tmp/strato-spiffe/bundle.pem \
        nohup swift run > /tmp/strato-control-plane.log 2>&1 &
        echo $! > /tmp/strato-control-plane.pid
      - echo "‚è≥ Waiting for control-plane to be ready..."
      - sleep 5
      - |
        for i in $(seq 1 60); do
          if curl -sf http://localhost:8080/health/live > /dev/null 2>&1; then
            echo "‚úÖ Control-plane with SPIFFE is ready!"
            echo "üìã Logs available at: /tmp/strato-control-plane.log"
            exit 0
          fi
          sleep 2
        done
        echo "‚ö†Ô∏è  Control-plane may not be fully ready. Check logs at /tmp/strato-control-plane.log"

  create-agent-config:
    desc: Create agent configuration file
    cmds:
      - echo "üìù Creating agent configuration..."
      - |
        cat > "{{.PROJECT_ROOT}}/config.toml" << 'EOF'
        # Strato Agent Configuration
        control_plane_url = "ws://localhost:8080/agent/ws"
        qemu_socket_dir = "/tmp/strato-qemu-sockets"
        log_level = "debug"
        network_mode = "user"
        EOF
      - echo "‚úÖ Agent config created at {{.PROJECT_ROOT}}/config.toml"

  create-agent-token:
    desc: Create agent registration token in database
    cmds:
      - echo "üîë Creating agent registration token..."
      - |
        TOKEN_VALUE=$(uuidgen)
        AGENT_NAME="strato-dev"

        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          INSERT INTO agent_registration_tokens (id, token, agent_name, is_used, expires_at, created_at)
          VALUES (
            gen_random_uuid(),
            '${TOKEN_VALUE}',
            '${AGENT_NAME}',
            false,
            NOW() + INTERVAL '24 hours',
            NOW()
          )
          ON CONFLICT DO NOTHING;
        " || echo "‚ö†Ô∏è  Failed to create agent registration token"

        REGISTRATION_URL="ws://localhost:8080/agent/ws?token=${TOKEN_VALUE}&name=${AGENT_NAME}"
        echo "${REGISTRATION_URL}" > /tmp/strato-agent-registration-url.txt

        echo "‚úÖ Agent registration token created!"
        echo "   Agent name: ${AGENT_NAME}"
        echo "   Registration URL saved to /tmp/strato-agent-registration-url.txt"

  start-agent:
    desc: Build and start the agent service
    cmds:
      - echo "ü§ñ Building and starting agent..."
      - echo "üî® Building agent..."
      - swift build --package-path "{{.PROJECT_ROOT}}/agent"
      - mkdir -p /tmp/strato-qemu-sockets
      - |
        if [ ! -f /tmp/strato-agent-registration-url.txt ]; then
          echo "‚ùå Agent registration URL not found at /tmp/strato-agent-registration-url.txt"
          exit 1
        fi
        REGISTRATION_URL=$(cat /tmp/strato-agent-registration-url.txt)

        echo "‚ñ∂Ô∏è  Starting agent with registration URL..."
        touch /tmp/strato-agent.log
        nohup swift run --package-path "{{.PROJECT_ROOT}}/agent" StratoAgent \
          --config-file "{{.PROJECT_ROOT}}/config.toml" \
          --registration-url "${REGISTRATION_URL}" > /tmp/strato-agent.log 2>&1 &
        echo $! > /tmp/strato-agent.pid
      - echo "‚úÖ Agent started!"
      - echo "üìã Logs available at:\ /tmp/strato-agent.log"
      - sleep 5

  create-test-vm:
    desc: Create test VM and setup test data via API
    cmds:
      - echo "üñ•Ô∏è  Creating test VM..."
      - echo "üë§ Setting up test user and organization..."
      - |
        # Create user
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          INSERT INTO users (id, username, email, display_name, is_system_admin, created_at, updated_at)
          VALUES (
            '00000000-0000-0000-0000-000000000001',
            'admin',
            'admin@strato.local',
            'System Administrator',
            true,
            NOW(),
            NOW()
          )
          ON CONFLICT (username) DO NOTHING;
        " || true

        # Create organization
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          INSERT INTO organizations (id, name, description, created_at, updated_at)
          VALUES (
            '00000000-0000-0000-0000-000000000001',
            'Default Organization',
            'Default organization for testing',
            NOW(),
            NOW()
          )
          ON CONFLICT (id) DO NOTHING;
        " || true

        # Link user to organization
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          INSERT INTO user_organizations (user_id, organization_id)
          VALUES (
            '00000000-0000-0000-0000-000000000001',
            '00000000-0000-0000-0000-000000000001'
          )
          ON CONFLICT DO NOTHING;
        " || true

        # Set current organization for user
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          UPDATE users
          SET current_organization_id = '00000000-0000-0000-0000-000000000001'
          WHERE id = '00000000-0000-0000-0000-000000000001';
        " || true

        # Create default project
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          INSERT INTO projects (id, organization_id, name, description, default_environment, environments, created_at, updated_at)
          VALUES (
            '00000000-0000-0000-0000-000000000001',
            '00000000-0000-0000-0000-000000000001',
            'Default Project',
            'Default project for testing',
            'development',
            ARRAY['development', 'staging', 'production'],
            NOW(),
            NOW()
          )
          ON CONFLICT (id) DO NOTHING;
        " || true
      - echo "üîê Setting up authorization relationships..."
      - |
        # User is admin of organization
        curl -sf -X POST \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer {{.SPICEDB_KEY}}" \
          -d '{
            "updates": [{
              "operation": "OPERATION_CREATE",
              "relationship": {
                "resource": {"objectType": "organization", "objectId": "00000000-0000-0000-0000-000000000001"},
                "relation": "admin",
                "subject": {"object": {"objectType": "user", "objectId": "00000000-0000-0000-0000-000000000001"}}
              }
            }]
          }' \
          http://localhost:8081/v1/relationships/write || true

        # Project belongs to organization
        curl -sf -X POST \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer {{.SPICEDB_KEY}}" \
          -d '{
            "updates": [{
              "operation": "OPERATION_CREATE",
              "relationship": {
                "resource": {"objectType": "project", "objectId": "00000000-0000-0000-0000-000000000001"},
                "relation": "organization",
                "subject": {"object": {"objectType": "organization", "objectId": "00000000-0000-0000-0000-000000000001"}}
              }
            }]
          }' \
          http://localhost:8081/v1/relationships/write || true
      - echo "‚úÖ Test user and organization created!"
      - echo "üîë Creating API key for admin user..."
      - |
        API_KEY_VALUE="sk_dev_test_key_$(uuidgen | tr -d '-' | head -c 32)"
        KEY_PREFIX=$(echo "${API_KEY_VALUE}" | head -c 16)
        KEY_HASH=$(echo -n "${API_KEY_VALUE}" | sha256sum | cut -d' ' -f1)

        # Get actual user ID
        ACTUAL_USER_ID=$(docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -t -A -c "SELECT id FROM users WHERE username = 'admin' LIMIT 1;")

        # Delete old test API key
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          DELETE FROM api_keys WHERE name = 'Development Test Key';
        " || true

        # Create new API key
        docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -c "
          INSERT INTO api_keys (id, user_id, name, key_hash, key_prefix, scopes, is_active, created_at, updated_at)
          VALUES (
            gen_random_uuid(),
            '${ACTUAL_USER_ID}',
            'Development Test Key',
            '${KEY_HASH}',
            '${KEY_PREFIX}',
            ARRAY['read', 'write'],
            true,
            NOW(),
            NOW()
          );
        " || true

        echo "‚úÖ API key created!"

        # Get project ID
        PROJECT_ID=$(docker exec {{.POSTGRES_CONTAINER}} psql -U {{.POSTGRES_USER}} -d {{.POSTGRES_DB}} -t -A -c "SELECT id FROM projects WHERE organization_id = '00000000-0000-0000-0000-000000000001' LIMIT 1;")

        echo ""
        echo "üñ•Ô∏è  Creating test VM via API..."
        VM_NAME="test-vm-$(uuidgen | head -c 8)"

        RESPONSE=$(curl -sf -X POST \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer ${API_KEY_VALUE}" \
          -d "{
            \"name\": \"${VM_NAME}\",
            \"description\": \"Test VM created by task dev\",
            \"templateName\": \"ubuntu-22.04\",
            \"projectId\": \"${PROJECT_ID}\",
            \"environment\": \"development\"
          }" \
          http://localhost:8080/vms 2>&1) || true

        if [ -n "$RESPONSE" ]; then
          echo "‚úÖ VM created successfully!"
          echo "   Response: ${RESPONSE:0:200}..."
        else
          echo "‚ö†Ô∏è  VM creation may have failed."
        fi
      - |
        echo ""
        echo "üéâ Development environment is ready!"
        echo ""
        echo "üìä Service Status:"
        echo "   ‚Ä¢ PostgreSQL:     http://localhost:5432"
        echo "   ‚Ä¢ SpiceDB:        http://localhost:8081"
        echo "   ‚Ä¢ Control Plane:  http://localhost:8080"
        echo "   ‚Ä¢ Agent:          Connected via WebSocket"
        echo ""
        echo "üìù Next steps:"
        echo "   ‚Ä¢ Check VM status: task check-vm"
        echo "   ‚Ä¢ View logs: task logs"
        echo "   ‚Ä¢ Open web UI: http://localhost:8080"

  # ============================================================================
  # Utility Tasks
  # ============================================================================
  check-vm:
    desc: Check if VMs are running via QEMU
    cmds:
      - echo "üîç Checking for running VMs..."
      - |
        OUTPUT=$(pgrep -a qemu 2>/dev/null || true)
        if [ -n "$OUTPUT" ]; then
          echo "‚úÖ Found running QEMU processes:"
          echo "$OUTPUT"
        else
          echo "‚ÑπÔ∏è  No QEMU processes found. VMs may not be running yet."
        fi

  status:
    desc: Show status of all services
    cmds:
      - echo "üìä Service Status"
      - echo ""
      - |
        # Check PostgreSQL
        PG_STATUS=$(docker ps --filter "name={{.POSTGRES_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$PG_STATUS" ]; then
          echo "PostgreSQL:    ‚úÖ Running ($PG_STATUS)"
        else
          echo "PostgreSQL:    ‚ùå Stopped"
        fi

        # Check SpiceDB
        SPICE_STATUS=$(docker ps --filter "name={{.SPICEDB_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$SPICE_STATUS" ]; then
          echo "SpiceDB:       ‚úÖ Running ($SPICE_STATUS)"
        else
          echo "SpiceDB:       ‚ùå Stopped"
        fi

        # Check Valkey
        VALKEY_STATUS=$(docker ps --filter "name={{.VALKEY_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$VALKEY_STATUS" ]; then
          echo "Valkey:        ‚úÖ Running ($VALKEY_STATUS)"
        else
          echo "Valkey:        ‚ùå Stopped"
        fi

        # Check Loki
        LOKI_STATUS=$(docker ps --filter "name={{.LOKI_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$LOKI_STATUS" ]; then
          echo "Loki:          ‚úÖ Running ($LOKI_STATUS)"
        else
          echo "Loki:          ‚ùå Stopped"
        fi

        # Check OTel Collector
        OTEL_STATUS=$(docker ps --filter "name={{.OTEL_COLLECTOR_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$OTEL_STATUS" ]; then
          echo "OTel Collector: ‚úÖ Running ($OTEL_STATUS)"
        else
          echo "OTel Collector: ‚ùå Stopped"
        fi

        # Check control-plane
        if [ -f /tmp/strato-control-plane.pid ]; then
          PID=$(cat /tmp/strato-control-plane.pid)
          if kill -0 "$PID" 2>/dev/null; then
            echo "Control Plane: ‚úÖ Running (PID: $PID)"
          else
            echo "Control Plane: ‚ùå Stopped"
          fi
        else
          echo "Control Plane: ‚ùå Stopped"
        fi

        # Check frontend
        if [ -f /tmp/strato-frontend.pid ]; then
          PID=$(cat /tmp/strato-frontend.pid)
          if kill -0 "$PID" 2>/dev/null; then
            echo "Frontend:      ‚úÖ Running (PID: $PID)"
          else
            echo "Frontend:      ‚ùå Stopped"
          fi
        else
          echo "Frontend:      ‚ùå Stopped"
        fi

        # Check agent
        if [ -f /tmp/strato-agent.pid ]; then
          PID=$(cat /tmp/strato-agent.pid)
          if kill -0 "$PID" 2>/dev/null; then
            echo "Agent:         ‚úÖ Running (PID: $PID)"
          else
            echo "Agent:         ‚ùå Stopped"
          fi
        else
          echo "Agent:         ‚ùå Stopped"
        fi

        # Check SPIRE Server
        SPIRE_SERVER_STATUS=$(docker ps --filter "name={{.SPIRE_SERVER_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$SPIRE_SERVER_STATUS" ]; then
          echo "SPIRE Server:  ‚úÖ Running ($SPIRE_SERVER_STATUS)"
        else
          echo "SPIRE Server:  ‚ùå Stopped"
        fi

        # Check SPIRE Agent
        SPIRE_AGENT_STATUS=$(docker ps --filter "name={{.SPIRE_AGENT_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$SPIRE_AGENT_STATUS" ]; then
          echo "SPIRE Agent:   ‚úÖ Running ($SPIRE_AGENT_STATUS)"
        else
          echo "SPIRE Agent:   ‚ùå Stopped"
        fi

        # Check Envoy
        ENVOY_STATUS=$(docker ps --filter "name={{.ENVOY_CONTAINER}}" --format "{{`{{.Status}}`}}" 2>/dev/null)
        if [ -n "$ENVOY_STATUS" ]; then
          echo "Envoy:         ‚úÖ Running ($ENVOY_STATUS)"
        else
          echo "Envoy:         ‚ùå Stopped"
        fi

  logs:
    desc: Show logs from all services
    cmds:
      - echo "üìã Service Logs"
      - echo ""
      - echo "=== Control Plane Logs ==="
      - |
        if [ -f /tmp/strato-control-plane.log ]; then
          tail -20 /tmp/strato-control-plane.log
        else
          echo "No logs found"
        fi
      - echo ""
      - echo "=== Frontend Logs ==="
      - |
        if [ -f /tmp/strato-frontend.log ]; then
          tail -20 /tmp/strato-frontend.log
        else
          echo "No logs found"
        fi
      - echo ""
      - echo "=== Agent Logs ==="
      - |
        if [ -f /tmp/strato-agent.log ]; then
          tail -20 /tmp/strato-agent.log
        else
          echo "No logs found"
        fi

  # ============================================================================
  # Cleanup Tasks
  # ============================================================================
  stop:
    desc: Stop all running services
    cmds:
      - echo "üõë Stopping all services..."
      - |
        # Stop any running QEMU VMs first (before killing agent)
        QEMU_PIDS=$(pgrep -f "qemu-system" 2>/dev/null || true)
        if [ -n "$QEMU_PIDS" ]; then
          echo "Stopping QEMU VMs: $QEMU_PIDS"
          echo "$QEMU_PIDS" | xargs kill 2>/dev/null || true
          sleep 2
          # Force kill any remaining
          REMAINING=$(pgrep -f "qemu-system" 2>/dev/null || true)
          if [ -n "$REMAINING" ]; then
            echo "Force killing remaining QEMU VMs: $REMAINING"
            echo "$REMAINING" | xargs kill -9 2>/dev/null || true
          fi
        fi

        # Stop frontend
        if [ -f /tmp/strato-frontend.pid ]; then
          PID=$(cat /tmp/strato-frontend.pid)
          if kill -0 "$PID" 2>/dev/null; then
            echo "Stopping frontend (PID: $PID)..."
            kill "$PID" 2>/dev/null || true
          fi
          rm -f /tmp/strato-frontend.pid
        fi
        # Also kill any process listening on port 3000
        FRONTEND_PIDS=$(lsof -ti :3000 2>/dev/null | grep -v "^$" || true)
        if [ -n "$FRONTEND_PIDS" ]; then
          echo "Stopping processes on port 3000: $FRONTEND_PIDS"
          echo "$FRONTEND_PIDS" | xargs kill 2>/dev/null || true
        fi

        # Stop agent - first try PID file, then find by process name
        if [ -f /tmp/strato-agent.pid ]; then
          PID=$(cat /tmp/strato-agent.pid)
          if kill -0 "$PID" 2>/dev/null; then
            echo "Stopping agent (PID: $PID)..."
            kill "$PID" 2>/dev/null || true
          fi
          rm -f /tmp/strato-agent.pid
        fi
        # Also kill any orphaned StratoAgent processes
        AGENT_PIDS=$(pgrep -f "StratoAgent" 2>/dev/null || true)
        if [ -n "$AGENT_PIDS" ]; then
          echo "Stopping orphaned StratoAgent processes: $AGENT_PIDS"
          echo "$AGENT_PIDS" | xargs kill 2>/dev/null || true
        fi

        # Stop control-plane - first try PID file, then find by port
        if [ -f /tmp/strato-control-plane.pid ]; then
          PID=$(cat /tmp/strato-control-plane.pid)
          if kill -0 "$PID" 2>/dev/null; then
            echo "Stopping control-plane (PID: $PID)..."
            kill "$PID" 2>/dev/null || true
          fi
          rm -f /tmp/strato-control-plane.pid
        fi
        # Also kill any process listening on port 8080 (the actual App binary)
        APP_PIDS=$(lsof -ti :8080 2>/dev/null | grep -v "^$" || true)
        if [ -n "$APP_PIDS" ]; then
          echo "Stopping processes on port 8080: $APP_PIDS"
          echo "$APP_PIDS" | xargs kill 2>/dev/null || true
          sleep 1
          # Force kill if still running
          REMAINING=$(lsof -ti :8080 2>/dev/null | grep -v "^$" || true)
          if [ -n "$REMAINING" ]; then
            echo "Force killing remaining processes on port 8080: $REMAINING"
            echo "$REMAINING" | xargs kill -9 2>/dev/null || true
          fi
        fi

        # Stop Docker containers
        echo "Stopping Docker containers..."
        docker stop {{.OTEL_COLLECTOR_CONTAINER}} 2>/dev/null || true
        docker stop {{.LOKI_CONTAINER}} 2>/dev/null || true
        docker stop {{.VALKEY_CONTAINER}} 2>/dev/null || true
        docker stop {{.SPICEDB_CONTAINER}} 2>/dev/null || true
        docker stop {{.POSTGRES_CONTAINER}} 2>/dev/null || true

        # Stop SPIFFE/SPIRE containers
        echo "Stopping SPIFFE/SPIRE containers..."
        docker stop {{.SPIRE_SERVER_CONTAINER}} 2>/dev/null || true
        docker stop {{.SPIRE_AGENT_CONTAINER}} 2>/dev/null || true
        docker stop {{.ENVOY_CONTAINER}} 2>/dev/null || true
      - echo "‚úÖ All services stopped!"

  clean:
    desc: Stop services and remove all containers and data
    deps: [stop]
    cmds:
      - echo "üßπ Cleaning up all resources..."
      - echo "Removing Docker containers..."
      - docker rm -f {{.OTEL_COLLECTOR_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.LOKI_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.VALKEY_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.SPICEDB_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.POSTGRES_CONTAINER}} 2>/dev/null || true
      - echo "Removing SPIFFE/SPIRE containers..."
      - docker rm -f {{.SPIRE_SERVER_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.SPIRE_AGENT_CONTAINER}} 2>/dev/null || true
      - docker rm -f {{.ENVOY_CONTAINER}} 2>/dev/null || true
      - echo "Removing Docker volumes..."
      - docker volume rm spire-server-data 2>/dev/null || true
      - docker volume rm spire-agent-data 2>/dev/null || true
      - echo "Removing log files..."
      - rm -f /tmp/strato-control-plane.log /tmp/strato-agent.log /tmp/strato-frontend.log
      - rm -f /tmp/strato-agent-registration-url.txt /tmp/strato-frontend.pid
      - echo "Removing SPIFFE/SPIRE temp directories..."
      - rm -rf /tmp/spire-server /tmp/spire-agent /tmp/spire-sockets /tmp/envoy
      - rm -f /tmp/spire-join-token.txt
      - rm -f /tmp/strato-agent-spiffe-config.toml
      - echo "‚úÖ Cleanup complete!"
